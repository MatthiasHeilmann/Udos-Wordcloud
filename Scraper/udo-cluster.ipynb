{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initialize\n",
    "import spacy\n",
    "from spacy.language import Language\n",
    "\n",
    "import requests\n",
    "import json\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "apiKey = \"hTLGygty2Sj5IB368rcArA63Xu29hW2r\"\n",
    "archiveUrl = f'https://api.nytimes.com/svc/archive/v1/#1/#2.json?api-key={apiKey}'\n",
    "\n",
    "def parseDoc(doc) -> list[str]:\n",
    "  headline = doc[\"headline\"][\"print_headline\"] or doc[\"headline\"][\"main\"]\n",
    "  leadPara = doc[\"lead_paragraph\"]\n",
    "  return str(headline + (\" \" if leadPara else \"\") + leadPara)\n",
    "\n",
    "# Disabling components not needed (optional, but useful if run on a large dataset)\n",
    "nlp = spacy.load(\"en_core_web_lg\", disable=[\"tok2vec\", \"parser\", \"senter\", \"lemmatizer\", \"tagger\", \"attribute_ruler\"])\n",
    "nlp.add_pipe(\"merge_noun_chunks\")\n",
    "nlp.add_pipe(\"merge_entities\")\n",
    "\n",
    "# Load the larger model for similarity calculation\n",
    "nlp_lg = nlp\n",
    "\n",
    "# Example text\n",
    "text = \"German Chancellor Angela Merkel died in 1936 in New York. She got shot by a mysterious terrorist, terror, terrorism\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://api.nytimes.com/svc/archive/v1/1963/10.json?api-key=hTLGygty2Sj5IB368rcArA63Xu29hW2r\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'HIDE KILLED PAKISTAN STATEMENT MALAYSIA CONGRESS PLOT ALABAMA SUITS STATEMENT MALAYSIA CONGRESS Killed'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Fetch\n",
    "\n",
    "print(archiveUrl.replace(\"#1\", \"1963\").replace(\"#2\", \"10\"))\n",
    "res = requests.get(archiveUrl.replace(\"#1\", \"1963\").replace(\"#2\", \"10\"))\n",
    "obj = json.loads(res.text)\n",
    "#words = \" \".join(map(lambda doc: parseDoc(doc), list(obj[\"response\"][\"docs\"])))\n",
    "words = \"HIDE KILLED PAKISTAN STATEMENT MALAYSIA CONGRESS PLOT ALABAMA SUITS STATEMENT MALAYSIA CONGRESS Killed\"\n",
    "\n",
    "words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Search\n",
    "\n",
    "def checkMatches(token, relevant_words):\n",
    "    token_lg = nlp_lg(token.text)\n",
    "    for comp in relevant_words.keys():\n",
    "        comp_lg = nlp_lg(comp)\n",
    "        similarity = token_lg.similarity(comp_lg)\n",
    "        if(similarity >= 0.8):\n",
    "            return (comp, similarity)\n",
    "    return False\n",
    "\n",
    "# Task 1: Extracting relevant words using the transformer-based model\n",
    "wordCount = {}\n",
    "matches: dict[str, dict] = {}\n",
    "doc_trf = nlp(words)\n",
    "for token in doc_trf:\n",
    "    if token.text in matches.keys():\n",
    "        matches[token.text][\"amount\"] = matches[token.text][\"amount\"] + 1\n",
    "    elif not token.is_stop and not token.is_punct:\n",
    "        matched = checkMatches(token, wordCount)\n",
    "        if(not matched):\n",
    "            wordCount[token.text] = {}\n",
    "            wordCount[token.text][\"amount\"] = 1\n",
    "        else:\n",
    "            if token.text in matches.keys():\n",
    "                matches[token.text][\"amount\"] = matches[token.text][\"amount\"] + 1\n",
    "            else:\n",
    "                matches[token.text] = {\n",
    "                    \"match\": matched[0],\n",
    "                    \"similarity\": matched[1],\n",
    "                    \"amount\": 1\n",
    "                }\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'HIDE': {'amount': 7,\n",
       "  'duplicates': {'KILLED': {'amount': 1, 'similarity': 0.8057828600326064},\n",
       "   'PLOT': {'amount': 1, 'similarity': 0.8421579273476232},\n",
       "   'SUITS': {'amount': 1, 'similarity': 0.8514908262080949}}},\n",
       " 'PAKISTAN': {'amount': 11,\n",
       "  'duplicates': {'MALAYSIA': {'amount': 2, 'similarity': 0.819214576299081},\n",
       "   'CONGRESS': {'amount': 2, 'similarity': 0.8360562373005461},\n",
       "   'ALABAMA': {'amount': 1, 'similarity': 0.8322161143134507}}},\n",
       " 'STATEMENT': {'amount': 3,\n",
       "  'duplicates': {'STATEMENT': {'amount': 1, 'similarity': 1.0}}},\n",
       " 'Killed': {'amount': 1}}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for m in matches.items():\n",
    "    if \"duplicates\" not in wordCount[m[1][\"match\"]]:\n",
    "        wordCount[m[1][\"match\"]][\"duplicates\"] = {}\n",
    "    wordCount[m[1][\"match\"]][\"duplicates\"][m[0]] = {\n",
    "        \"amount\": m[1][\"amount\"],\n",
    "        \"similarity\": m[1][\"similarity\"]\n",
    "    }\n",
    "    wordCount[m[1][\"match\"]][\"amount\"] = wordCount[m[1][\"match\"]][\"amount\"] + m[1][\"amount\"]\n",
    "\n",
    "wordCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'HIDE': {'amount': 4, 'duplicates': {'KILLED': 1, 'PLOT': 1, 'SUITS': 1}}, 'PAKISTAN': {'amount': 6, 'duplicates': {'MALAYSIA': 2, 'CONGRESS': 2, 'ALABAMA': 1}}, 'STATEMENT': {'amount': 2, 'duplicates': {'STATEMENT': 1}}, 'Killed': {'amount': 1}}\n",
      "\n",
      "--------------------\n",
      "\n",
      "{'KILLED': {'match': 'HIDE', 'similarity': 0.8057828600326064, 'amount': 1}, 'MALAYSIA': {'match': 'PAKISTAN', 'similarity': 0.819214576299081, 'amount': 2}, 'CONGRESS': {'match': 'PAKISTAN', 'similarity': 0.8360562373005461, 'amount': 2}, 'PLOT': {'match': 'HIDE', 'similarity': 0.8421579273476232, 'amount': 1}, 'ALABAMA': {'match': 'PAKISTAN', 'similarity': 0.8322161143134507, 'amount': 1}, 'SUITS': {'match': 'HIDE', 'similarity': 0.8514908262080949, 'amount': 1}, 'STATEMENT': {'match': 'STATEMENT', 'similarity': 1.0, 'amount': 1}}\n"
     ]
    }
   ],
   "source": [
    "print(wordCount)\n",
    "print(\"\\n--------------------\\n\")\n",
    "print(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "f-string: unmatched '[' (3698956332.py, line 16)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[24], line 16\u001b[1;36m\u001b[0m\n\u001b[1;33m    print(f\"{tag[\"name\"]}: {spacy.explain(tag)}\")\u001b[0m\n\u001b[1;37m                  ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m f-string: unmatched '['\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "taggers = [{\n",
    "    \"name\": \"Taggers\",\n",
    "    \"values\": [\n",
    "        \"$\", \"''\", \",\", \"-LRB-\", \"-RRB-\", \".\", \":\", \"ADD\", \"AFX\", \"CC\", \"CD\", \"DT\", \"EX\", \"FW\", \"HYPH\", \"IN\", \"JJ\", \"JJR\", \"JJS\", \"LS\", \"MD\", \"NFP\", \"NN\", \"NNP\", \"NNPS\", \"NNS\", \"PDT\", \"POS\", \"PRP\", \"PRP$\", \"RB\", \"RBR\", \"RBS\", \"RP\", \"SYM\", \"TO\", \"UH\", \"VB\", \"VBD\", \"VBG\", \"VBN\", \"VBP\", \"VBZ\", \"WDT\", \"WP\", \"WP$\", \"WRB\", \"XX\", \"_SP\", \"``\"\n",
    "    ]\n",
    "}]\n",
    "\n",
    "for tagger in taggers:\n",
    "    print(tagger[\"name\"])\n",
    "    print(tagger[\"values\"])\n",
    "\n",
    "for tagger in taggers:\n",
    "\n",
    "    for tag in tagger[\"values\"]:\n",
    "        print(f\"{tag[\"name\"]}: {spacy.explain(tag)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
